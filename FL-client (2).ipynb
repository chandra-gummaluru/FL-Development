{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt  # This is python's popular plotting library.\n",
    "# This is to ensure matplotlib plots inline and does not try to open a new window.\n",
    "%matplotlib inline  \n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import pandas as  pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "trainset = datasets.MNIST(\n",
    "    root = './data',\n",
    "    train = True,\n",
    "    download = False, \n",
    "    transform = transform\n",
    ")\n",
    "testset = datasets.MNIST(\n",
    "    root = './data',\n",
    "    train = False,\n",
    "    download = False,\n",
    "    transform = transform\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size = 4,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit 0: 5923 samples\n",
      "digit 1: 6742 samples\n",
      "digit 2: 5958 samples\n",
      "digit 3: 6131 samples\n",
      "digit 4: 5842 samples\n",
      "digit 5: 5421 samples\n",
      "digit 6: 5918 samples\n",
      "digit 7: 6265 samples\n",
      "digit 8: 5851 samples\n",
      "digit 9: 5949 samples\n",
      "number of selected data = 60000\n",
      "original dataset:\n",
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "\n",
      "selected trainset:\n",
      "torch.Size([4, 1, 28, 28]) (should be [4, 1, 28, 28])\n",
      "torch.Size([4]) (should be [4])\n",
      "tensor([1, 8, 7, 3])\n",
      "\n",
      "testset:\n",
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4])\n",
      "tensor([7, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# extract a subset of the digits as local client data\n",
    "# local_client_digits = [0,1,2,7,9]\n",
    "# local_client_digits = [3,4,5,6,8]\n",
    "local_client_digits = [0,1,2,3,4,5,6,7,8,9]\n",
    "idx = []\n",
    "for i in local_client_digits:\n",
    "    idx_i = (trainset.targets == i).nonzero()[:,0].tolist()\n",
    "    print(\"digit %d: %d samples\" %(i, len(idx_i)))\n",
    "    idx += idx_i\n",
    "\n",
    "print(\"number of selected data = {}\".format(len(idx)))\n",
    "# selected_data = trainset.data[idx].unsqueeze(1)\n",
    "# print(selected_data.shape)\n",
    "# selected_labels = trainset.targets[idx]\n",
    "# selected_trainset = TensorDataset(selected_data, selected_labels)\n",
    "# print(\"selected labels = {}\\n\".format(selected_labels))\n",
    "\n",
    "# for some mysterious reason, when i do this, it works, but when i switch to the 4 lines above, it only recognized 1/3 digits??\n",
    "trainset.data = trainset.data[idx]\n",
    "trainset.targets = trainset.targets[idx]\n",
    "\n",
    "\n",
    "# must shuffle data to avoid learning all ones, all twos, all threes in one go\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size = 4,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "# check if we have the correct dimensions\n",
    "print(\"original dataset:\")\n",
    "print(trainset.data.shape)\n",
    "print(trainset.targets.shape)\n",
    "\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    print(\"\\nselected trainset:\")\n",
    "    print(\"{} (should be [4, 1, 28, 28])\".format(data[0].shape))\n",
    "    print(\"{} (should be [4])\".format(data[1].shape))\n",
    "    print(data[1])\n",
    "    break\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    print(\"\\ntestset:\")\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)\n",
    "    print(data[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize each image\n",
    "def showTensor(aTensor):\n",
    "    plt.figure()\n",
    "    plt.imshow(aTensor.numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "showTensor(trainset.data[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, \n",
    "                               kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, \n",
    "                               kernel_size=5, stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=50*4*4, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x.float()))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x)) #do we need to convert to float here as well?\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Net()\n",
    "#compressor(model_1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_1.conv1.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = model_1.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1,  1000 Mini Batches] loss: 0.898\n",
      "[Epoch 1,  2000 Mini Batches] loss: 0.221\n",
      "[Epoch 1,  3000 Mini Batches] loss: 0.150\n",
      "[Epoch 1,  4000 Mini Batches] loss: 0.127\n",
      "[Epoch 1,  5000 Mini Batches] loss: 0.101\n",
      "[Epoch 1,  6000 Mini Batches] loss: 0.086\n",
      "[Epoch 1,  7000 Mini Batches] loss: 0.082\n",
      "[Epoch 1,  8000 Mini Batches] loss: 0.074\n",
      "[Epoch 1,  9000 Mini Batches] loss: 0.090\n",
      "[Epoch 1, 10000 Mini Batches] loss: 0.065\n",
      "[Epoch 1, 11000 Mini Batches] loss: 0.060\n",
      "[Epoch 1, 12000 Mini Batches] loss: 0.066\n",
      "[Epoch 1, 13000 Mini Batches] loss: 0.052\n",
      "[Epoch 1, 14000 Mini Batches] loss: 0.055\n",
      "[Epoch 1, 15000 Mini Batches] loss: 0.056\n",
      "Done Training\n",
      "1.58 minutes\n"
     ]
    }
   ],
   "source": [
    "def train(net, train_data, optimizer):\n",
    "    start = time.time()\n",
    "    for epoch in range(1): # no. of epochs!!!!!!!!\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_data, 0):\n",
    "            # data pixels and labels to GPU if available\n",
    "            inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
    "            # set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # propagate the loss backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print for mini batches\n",
    "            running_loss += loss.item()\n",
    "            if i % 1000 == 999:  # every 1000 mini batches\n",
    "                print('[Epoch %d, %5d Mini Batches] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss/1000))\n",
    "                running_loss = 0.0\n",
    "    end = time.time()\n",
    "    print('Done Training')\n",
    "    print('%0.2f minutes' %((end - start) / 60))\n",
    "    \n",
    "train(net, trainloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0631, -0.0434, -0.0322, -0.1848,  0.2348],\n",
       "          [ 0.0392, -0.1756, -0.0527,  0.0816,  0.1513],\n",
       "          [ 0.1049, -0.1922,  0.2122, -0.1849, -0.1316],\n",
       "          [ 0.2238,  0.0304,  0.2147, -0.0231, -0.2041],\n",
       "          [-0.0438,  0.0251,  0.1054, -0.1326, -0.0197]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0700,  0.2463, -0.1869, -0.2587, -0.2072],\n",
       "          [ 0.0689,  0.1919,  0.2239, -0.1451, -0.3733],\n",
       "          [-0.1195,  0.2283,  0.5042,  0.2202, -0.2375],\n",
       "          [-0.1791, -0.0886,  0.3388,  0.3580,  0.0849],\n",
       "          [-0.1794, -0.2106,  0.0807, -0.0902,  0.1454]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0824,  0.2138,  0.1598,  0.0342,  0.0775],\n",
       "          [ 0.1746,  0.1864,  0.1585,  0.3540,  0.2186],\n",
       "          [-0.1090, -0.0339,  0.0691, -0.0036,  0.1188],\n",
       "          [-0.1496, -0.2535, -0.0168, -0.1987,  0.1627],\n",
       "          [-0.2880, -0.2172, -0.1835, -0.1985, -0.2126]]],\n",
       "\n",
       "\n",
       "        [[[-0.0990, -0.1784,  0.2339,  0.1477,  0.0573],\n",
       "          [-0.0335,  0.2854,  0.2565,  0.1000, -0.0840],\n",
       "          [ 0.2110,  0.1038,  0.1213, -0.0864, -0.1184],\n",
       "          [ 0.1865,  0.1108,  0.1236, -0.2997, -0.2464],\n",
       "          [ 0.1799,  0.0129, -0.2390, -0.0007, -0.0520]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1522,  0.0901,  0.2436, -0.0309,  0.1707],\n",
       "          [ 0.0613,  0.0735, -0.1004, -0.0825, -0.1833],\n",
       "          [-0.0974, -0.2484, -0.1516, -0.0646, -0.0637],\n",
       "          [-0.1668,  0.0346, -0.1857, -0.0105,  0.2275],\n",
       "          [-0.0973,  0.0511,  0.0187,  0.1508,  0.2470]]],\n",
       "\n",
       "\n",
       "        [[[-0.0525,  0.1114,  0.1701,  0.3033,  0.0634],\n",
       "          [-0.0204,  0.3241,  0.2597,  0.0568,  0.0061],\n",
       "          [ 0.1522, -0.2331, -0.1829, -0.0811, -0.0965],\n",
       "          [-0.0446, -0.1131, -0.2106, -0.0083,  0.1507],\n",
       "          [-0.2037, -0.0024, -0.1308, -0.1088,  0.1635]]],\n",
       "\n",
       "\n",
       "        [[[-0.3051, -0.2113,  0.1197,  0.3468,  0.1534],\n",
       "          [-0.0142,  0.1380,  0.3270,  0.2811, -0.2707],\n",
       "          [-0.1395,  0.0168,  0.3791, -0.1443, -0.2629],\n",
       "          [ 0.0427,  0.1217,  0.1840,  0.0425, -0.0115],\n",
       "          [ 0.1845, -0.0114,  0.1378, -0.0255, -0.2804]]],\n",
       "\n",
       "\n",
       "        [[[-0.0960, -0.1264,  0.0534,  0.0069, -0.0860],\n",
       "          [-0.1801, -0.0375, -0.0585, -0.0613,  0.1490],\n",
       "          [-0.1369, -0.2345, -0.0383, -0.1061,  0.0420],\n",
       "          [-0.1720,  0.0461, -0.2277,  0.1274, -0.0578],\n",
       "          [-0.1049, -0.1921,  0.1732,  0.0560,  0.0906]]],\n",
       "\n",
       "\n",
       "        [[[-0.2188, -0.0646, -0.0556, -0.3085, -0.2439],\n",
       "          [-0.0025, -0.2868, -0.3308, -0.0274, -0.0919],\n",
       "          [-0.2310, -0.2986, -0.1520, -0.0942, -0.0904],\n",
       "          [ 0.3463,  0.3204,  0.1917,  0.4003,  0.3017],\n",
       "          [ 0.1715,  0.3844,  0.4161,  0.0898,  0.1471]]],\n",
       "\n",
       "\n",
       "        [[[-0.0575, -0.1503, -0.2011, -0.2319, -0.2267],\n",
       "          [-0.1381, -0.0844, -0.1483, -0.2002,  0.0149],\n",
       "          [-0.0194, -0.1657, -0.1405, -0.2069, -0.0274],\n",
       "          [ 0.1162, -0.1546, -0.0013,  0.1430, -0.0771],\n",
       "          [-0.0360,  0.0937, -0.0022, -0.0659,  0.2687]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0944, -0.0192, -0.1028, -0.1697,  0.0417],\n",
       "          [ 0.1404, -0.0394, -0.1066, -0.1504, -0.2260],\n",
       "          [ 0.1362, -0.1716,  0.0686,  0.0776, -0.0532],\n",
       "          [ 0.0152, -0.1664,  0.0286, -0.1270,  0.0701],\n",
       "          [ 0.1667, -0.1476,  0.0634, -0.0836,  0.1751]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0581,  0.2249,  0.0478,  0.0480, -0.0969],\n",
       "          [ 0.1756,  0.0040,  0.0797, -0.1316, -0.0264],\n",
       "          [-0.2525, -0.1514, -0.1965,  0.0199, -0.1373],\n",
       "          [-0.1899,  0.1147, -0.0214, -0.1125,  0.2228],\n",
       "          [ 0.1409,  0.1111,  0.0145,  0.1911,  0.2112]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0312, -0.0882,  0.2864,  0.2417, -0.0499],\n",
       "          [-0.0992, -0.1432,  0.2689, -0.0444, -0.3431],\n",
       "          [-0.1163,  0.1616,  0.0246,  0.1959, -0.3331],\n",
       "          [-0.2111,  0.1043,  0.2418,  0.2323, -0.0369],\n",
       "          [ 0.0157, -0.1365,  0.0126,  0.1281,  0.2241]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3342,  0.3144,  0.2467,  0.4366,  0.4436],\n",
       "          [ 0.1254, -0.0464, -0.0870,  0.0006,  0.0071],\n",
       "          [-0.2455, -0.0390,  0.0457, -0.2387, -0.1314],\n",
       "          [-0.2285, -0.3410, -0.1997, -0.2296, -0.0960],\n",
       "          [ 0.1211, -0.1391,  0.1175, -0.1306, -0.0573]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1194,  0.0938, -0.1600, -0.0892, -0.1193],\n",
       "          [-0.1747, -0.0789, -0.1268,  0.0096,  0.1252],\n",
       "          [-0.1047, -0.1539, -0.1223, -0.1669, -0.0844],\n",
       "          [ 0.1885,  0.1858, -0.1690,  0.1640, -0.0119],\n",
       "          [-0.0602, -0.0611,  0.0479,  0.1256,  0.2964]]],\n",
       "\n",
       "\n",
       "        [[[-0.0424, -0.0212, -0.0257, -0.0576, -0.0307],\n",
       "          [ 0.1068,  0.0806, -0.1412,  0.0115, -0.1031],\n",
       "          [-0.0602, -0.2591, -0.1388, -0.1441,  0.2186],\n",
       "          [-0.2383, -0.0593,  0.2877,  0.2440,  0.0862],\n",
       "          [ 0.1333,  0.2959,  0.0230, -0.0094, -0.1831]]],\n",
       "\n",
       "\n",
       "        [[[-0.1039,  0.1681, -0.1195, -0.1706,  0.1084],\n",
       "          [-0.1711,  0.0094,  0.0872, -0.0564, -0.0544],\n",
       "          [ 0.0749,  0.1487, -0.0430, -0.3091, -0.3075],\n",
       "          [ 0.0245,  0.2089,  0.2648,  0.1858, -0.2084],\n",
       "          [ 0.1186,  0.0955, -0.0276,  0.0749,  0.2467]]],\n",
       "\n",
       "\n",
       "        [[[-0.2081,  0.1319,  0.2212,  0.2633, -0.0335],\n",
       "          [-0.2426, -0.0943, -0.0815,  0.2971,  0.2495],\n",
       "          [-0.1837, -0.1411,  0.0044, -0.0009,  0.2968],\n",
       "          [-0.1577, -0.0174,  0.1003,  0.3044,  0.1291],\n",
       "          [-0.2078,  0.1423, -0.0302,  0.0597,  0.2867]]],\n",
       "\n",
       "\n",
       "        [[[-0.0532, -0.1565, -0.1248,  0.0541, -0.1053],\n",
       "          [ 0.0549, -0.1717,  0.0071, -0.0513, -0.1464],\n",
       "          [ 0.3153,  0.1568,  0.1084,  0.0804, -0.1385],\n",
       "          [-0.1159,  0.1775,  0.2481, -0.0232,  0.0438],\n",
       "          [-0.2271, -0.0796,  0.2281,  0.1628, -0.1427]]],\n",
       "\n",
       "\n",
       "        [[[-0.2066, -0.1969, -0.1019,  0.2275,  0.0739],\n",
       "          [ 0.0517,  0.0044, -0.2533,  0.2390,  0.0808],\n",
       "          [-0.2758, -0.2540, -0.1293,  0.2677,  0.0956],\n",
       "          [-0.1294, -0.1104, -0.0312,  0.3477,  0.2168],\n",
       "          [-0.1189, -0.0647,  0.2696,  0.1922, -0.1494]]]], requires_grad=True)"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weights = net.conv1.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_weights = net.conv2.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_weights = net.fc1.weight.detach().numpy()\n",
    "fc2_weights = net.fc2.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#conv1_weight_orig = model_1.conv1.weight_orig.detach().numpy()\n",
    "flattened_conv1_orig = conv1_weights.ravel()\n",
    "print(flattened_conv1_orig.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "flattened_conv2_orig = conv2_weights.ravel()\n",
    "print(flattened_conv2_orig.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "flattened_fc1_orig = fc1_weights.ravel()\n",
    "flattened_fc2_orig = fc2_weights.ravel()\n",
    "print(flattened_fc1_orig.size)\n",
    "print(flattened_fc2_orig.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_index(max_range, dropout_rate=0.2, random_seed=10): \n",
    "    np.random.seed(random_seed)\n",
    "    random_list = np.random.choice(range(max_range), int(max_range * dropout_rate) , replace=False)\n",
    "    random_list.sort()\n",
    "    return random_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression(model, dropout_rate=0.2, random_seed=10):\n",
    "    compressed_weights = {}\n",
    "    zero_indices = {}\n",
    "    for name, m in model.named_children():\n",
    "        orig_weights = m.weight.detach().numpy()\n",
    "        #print(orig_weights.shape)\n",
    "        flattened_orig = orig_weights.ravel()\n",
    "        random_indices = random_index(flattened_orig.size, dropout_rate=dropout_rate, random_seed=random_seed)\n",
    "        compressed_flattened_weights = np.delete(flattened_orig, random_indices)\n",
    "        compressed_weights[name] = {\n",
    "            'size': flattened_orig.size,\n",
    "            'shape': orig_weights.shape,\n",
    "            'weights': compressed_flattened_weights,\n",
    "            'bias': m.bias\n",
    "        }\n",
    "        #print(compressed_flattened_weights.nbytes)\n",
    "    return compressed_weights\n",
    "# for layer in m.children():\n",
    "#     weights = list(layer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv1': {'size': 500, 'shape': (20, 1, 5, 5), 'weights': array([-0.06311929, -0.04336417, -0.03222009, -0.18482783,  0.23477986,\n",
      "       -0.17557675, -0.05274175,  0.08155678,  0.10492679,  0.21216552,\n",
      "       -0.1315798 ,  0.03035231,  0.21470737, -0.02308621, -0.20410906,\n",
      "       -0.04378352,  0.02508779,  0.10536567, -0.13259022,  0.06995094,\n",
      "       -0.18693781, -0.25869635, -0.20719339,  0.0688824 ,  0.19190998,\n",
      "        0.22387221, -0.11949172,  0.5042266 ,  0.22017145, -0.23754418,\n",
      "       -0.17912184,  0.35795048,  0.08493593, -0.17939936, -0.21056058,\n",
      "        0.0807202 ,  0.08239484,  0.21375096,  0.1598448 ,  0.03419674,\n",
      "        0.07746512,  0.18642843,  0.1585452 ,  0.35403088, -0.10900239,\n",
      "       -0.03386626,  0.06910697, -0.00361548,  0.11876479, -0.14956324,\n",
      "       -0.01676279, -0.19868909,  0.16274281, -0.2880245 , -0.2171544 ,\n",
      "       -0.19847305, -0.21261367, -0.1783827 ,  0.23390386,  0.14768569,\n",
      "        0.05732898, -0.03354806,  0.28540045,  0.10003971, -0.08402345,\n",
      "        0.10376859,  0.12128292, -0.08641922, -0.11844133,  0.18645377,\n",
      "        0.11076227,  0.12359206, -0.24637853,  0.17990698,  0.01293347,\n",
      "       -0.23902096, -0.00066424, -0.05199676,  0.15223831, -0.03090136,\n",
      "        0.1706753 ,  0.06132434,  0.07354882, -0.08252044, -0.1833376 ,\n",
      "       -0.09738484, -0.24844263, -0.15159015, -0.06462128, -0.16680808,\n",
      "        0.03457557, -0.1857051 , -0.01054476,  0.2274532 , -0.09733037,\n",
      "        0.05110665,  0.01865614,  0.15082762,  0.24702273,  0.11137313,\n",
      "        0.17014058,  0.30334875,  0.06335793, -0.02042397,  0.05684656,\n",
      "        0.15215129, -0.23314157, -0.1829173 , -0.09650438, -0.04464283,\n",
      "       -0.11312775, -0.00827621,  0.15072623, -0.20372817, -0.00235443,\n",
      "       -0.13075568, -0.10876286,  0.1635315 , -0.30509487,  0.11967033,\n",
      "        0.34677488,  0.15339887, -0.01419157,  0.1379949 ,  0.32695362,\n",
      "        0.28114113, -0.27065408,  0.0167949 ,  0.3790568 , -0.14425997,\n",
      "        0.04269615,  0.12169367,  0.18403344,  0.04250525, -0.01150926,\n",
      "       -0.02547173, -0.2804192 , -0.0960038 , -0.12636371,  0.05342145,\n",
      "        0.00687022, -0.08595353, -0.18006276, -0.03754183, -0.06133862,\n",
      "       -0.23447585, -0.03832271,  0.04609166, -0.22774346,  0.12739566,\n",
      "       -0.05775582, -0.10487886, -0.19213149,  0.17317739,  0.05601683,\n",
      "        0.09060785, -0.21875723, -0.06455037, -0.05556337, -0.30851233,\n",
      "       -0.00252712, -0.28675556, -0.3308392 , -0.02743041, -0.09192058,\n",
      "       -0.23099354, -0.2985642 , -0.0942383 , -0.09036797,  0.34631518,\n",
      "        0.32044226,  0.19171591,  0.40034005,  0.30168113,  0.17151405,\n",
      "        0.38440335,  0.41612354,  0.147052  , -0.05746159, -0.15029149,\n",
      "       -0.20113975, -0.23187837, -0.1380557 , -0.08444954, -0.14833006,\n",
      "       -0.2002269 , -0.01940021, -0.16567028, -0.20689009, -0.02735784,\n",
      "        0.11616244, -0.00132112,  0.14303562, -0.07708928, -0.0360266 ,\n",
      "        0.0937325 , -0.00221089, -0.06592937,  0.09439691, -0.01919335,\n",
      "       -0.16969316,  0.04169891,  0.14036779, -0.03942142, -0.10664032,\n",
      "       -0.15038802, -0.2259892 ,  0.13620757,  0.06855891,  0.07760766,\n",
      "        0.01519155,  0.0285896 , -0.12698567,  0.07007347,  0.16670065,\n",
      "       -0.14762133, -0.08364613,  0.05805264,  0.04803294, -0.09691403,\n",
      "        0.00397673,  0.07966116, -0.13162766, -0.02638655, -0.25248948,\n",
      "       -0.15138882,  0.01985644, -0.1899177 ,  0.11473177, -0.0214199 ,\n",
      "       -0.11246977,  0.22281247,  0.14086531,  0.11111092,  0.01451576,\n",
      "        0.19112496,  0.21120168,  0.03117938, -0.08816919,  0.28644577,\n",
      "        0.24171716, -0.04990305, -0.09919433,  0.26890734, -0.34312603,\n",
      "        0.16164023,  0.02455673, -0.33305925, -0.21110381,  0.2322837 ,\n",
      "       -0.0368842 , -0.13649411,  0.01256918,  0.12807572,  0.22413361,\n",
      "        0.33423248,  0.31444687,  0.44360512,  0.12536404, -0.0463632 ,\n",
      "        0.00062722,  0.00712462, -0.24551307, -0.03896587, -0.13142203,\n",
      "       -0.22848731, -0.34097493, -0.19969797, -0.09601162,  0.12110768,\n",
      "       -0.13914068,  0.11750641, -0.13061701, -0.0572606 ,  0.11940839,\n",
      "       -0.15997022, -0.08916997, -0.11934154, -0.17469238, -0.07886092,\n",
      "       -0.12678438,  0.00956507,  0.1251634 , -0.10473472, -0.15388551,\n",
      "       -0.08437206,  0.18854359,  0.18575723, -0.06106786,  0.04787935,\n",
      "        0.12561217,  0.29644373, -0.02124361, -0.02574915, -0.03067889,\n",
      "        0.10679848, -0.14122684,  0.01153627, -0.10313472, -0.06018857,\n",
      "       -0.25914925, -0.13880302, -0.14410953,  0.21863905, -0.23833361,\n",
      "       -0.05925542,  0.24395742,  0.08623981,  0.13330807,  0.29585388,\n",
      "        0.02301676, -0.00937773, -0.18311761, -0.10385232,  0.16813119,\n",
      "       -0.1194805 , -0.17059886,  0.1083758 , -0.17110369,  0.0093891 ,\n",
      "        0.08718619, -0.05636524, -0.05442939,  0.07486071,  0.14865293,\n",
      "       -0.04295293, -0.30913022, -0.30749437,  0.02447358,  0.26484355,\n",
      "        0.1857686 , -0.20837481,  0.11859348,  0.09546705, -0.02755789,\n",
      "        0.07487353,  0.24668077,  0.13192442,  0.22123884,  0.26329926,\n",
      "       -0.03354701, -0.24258563, -0.08154406,  0.29714268, -0.18367346,\n",
      "       -0.141071  ,  0.00437148, -0.00094939,  0.2968406 , -0.01741797,\n",
      "        0.10034985,  0.3043762 ,  0.12911357, -0.20776042,  0.14232665,\n",
      "       -0.03022614,  0.28670055, -0.05319131, -0.15646532, -0.12475272,\n",
      "        0.0540599 , -0.10527609,  0.05485275, -0.17173444,  0.00705766,\n",
      "       -0.05132205, -0.14644733,  0.31530184,  0.10841318, -0.13854226,\n",
      "       -0.11594435,  0.1775075 , -0.0231608 ,  0.0437705 , -0.07956541,\n",
      "        0.16276854, -0.1427291 , -0.19687632, -0.10185818,  0.22746463,\n",
      "        0.0738742 ,  0.05171255,  0.00441133, -0.25334102,  0.23904566,\n",
      "        0.08080645, -0.275794  , -0.25404167, -0.12929076,  0.2677045 ,\n",
      "       -0.12938675, -0.11043491, -0.0312057 ,  0.34767908,  0.21675375,\n",
      "       -0.11889163, -0.06474739,  0.26962668,  0.19215614, -0.14941974],\n",
      "      dtype=float32), 'bias': Parameter containing:\n",
      "tensor([-0.0043, -0.1102,  0.0247,  0.0222, -0.0254,  0.1691,  0.1220, -0.1632,\n",
      "         0.0741, -0.3533, -0.0546,  0.0616, -0.0791, -0.0884, -0.1745, -0.0998,\n",
      "         0.2434,  0.2171,  0.1365,  0.0053], requires_grad=True)}, 'conv2': {'size': 25000, 'shape': (50, 20, 5, 5), 'weights': array([-0.00453251, -0.02780537, -0.02151779, ...,  0.02937722,\n",
      "        0.02332496,  0.00186012], dtype=float32), 'bias': Parameter containing:\n",
      "tensor([ 0.0368,  0.0404,  0.0027,  0.0239, -0.0421,  0.0402,  0.0034, -0.0035,\n",
      "        -0.0011, -0.0060,  0.0386, -0.0314, -0.0234,  0.0036, -0.0183,  0.0098,\n",
      "         0.0071, -0.0035, -0.0130,  0.0427, -0.0399, -0.0181, -0.0326, -0.0137,\n",
      "         0.0381, -0.0356, -0.0088,  0.0154,  0.0012, -0.0379, -0.0162,  0.0018,\n",
      "         0.0158,  0.0265, -0.0327, -0.0363, -0.0055, -0.0202, -0.0322,  0.0009,\n",
      "         0.0393,  0.0181,  0.0189, -0.0211,  0.0106, -0.0288,  0.0184, -0.0093,\n",
      "        -0.0379,  0.0002], requires_grad=True)}, 'fc1': {'size': 400000, 'shape': (500, 800), 'weights': array([-0.02270204, -0.01562434,  0.01734661, ...,  0.00369354,\n",
      "        0.01384644, -0.00081381], dtype=float32), 'bias': Parameter containing:\n",
      "tensor([ 1.5547e-02, -1.5065e-02, -2.9426e-02, -2.2955e-02,  2.9820e-02,\n",
      "         2.9105e-02, -2.6783e-02,  3.3889e-03, -3.1064e-02,  2.9403e-02,\n",
      "        -2.0529e-02, -1.6440e-02,  1.9539e-02,  3.6522e-03,  2.6981e-02,\n",
      "        -3.0834e-02,  2.3800e-02, -3.2205e-02,  1.7278e-03, -3.1630e-02,\n",
      "        -9.1810e-04, -2.8120e-02, -2.1463e-02,  3.2509e-02,  3.7503e-02,\n",
      "         2.1457e-02,  2.1334e-03, -1.0318e-02, -1.5160e-02,  1.9734e-02,\n",
      "        -6.7985e-03,  8.5424e-03,  2.8780e-02,  3.2385e-02, -1.4450e-02,\n",
      "         3.2223e-03,  1.4043e-02, -2.2789e-02, -4.4880e-03,  3.0246e-02,\n",
      "         1.0251e-04, -1.0093e-02, -1.7509e-02, -2.7424e-02, -1.3403e-02,\n",
      "         3.3308e-03,  4.9422e-03, -1.3517e-02, -3.1035e-02,  2.4120e-02,\n",
      "        -3.1494e-02, -1.6268e-02, -7.2758e-03, -1.0624e-02,  1.9502e-02,\n",
      "        -2.8990e-02,  2.0858e-02, -1.7346e-02, -3.1991e-02, -2.2510e-02,\n",
      "         2.5397e-02,  2.9735e-02,  1.9961e-02,  1.7945e-02, -1.2064e-02,\n",
      "        -1.9972e-02, -1.9667e-02, -2.6484e-03, -1.4822e-02,  2.1158e-02,\n",
      "         1.4510e-02,  1.2445e-02,  8.9405e-03,  3.1230e-02, -2.9580e-02,\n",
      "        -1.1767e-03, -3.8236e-03,  5.6480e-03, -1.8311e-02, -2.5340e-02,\n",
      "        -3.1727e-02,  2.7833e-02, -3.2825e-02,  1.0065e-02,  2.1310e-03,\n",
      "         2.0024e-02,  8.9865e-03, -4.4280e-03, -2.4276e-02, -8.7174e-03,\n",
      "        -1.4009e-03, -2.5282e-02,  1.3438e-02,  1.3415e-02,  3.0557e-02,\n",
      "         1.6970e-02,  2.1850e-02, -1.7820e-02, -2.0451e-03, -1.3843e-02,\n",
      "        -1.7594e-02, -2.2820e-02, -9.8427e-03, -5.9976e-03, -1.2901e-02,\n",
      "         3.4625e-02,  2.0282e-02,  3.0938e-02, -2.4032e-02, -2.9158e-02,\n",
      "        -2.0278e-03, -1.4055e-02,  8.1247e-03, -1.8665e-02, -1.2057e-02,\n",
      "         2.2710e-02, -3.4936e-02, -7.6712e-03,  1.4239e-02, -2.1577e-02,\n",
      "        -9.9840e-05, -5.9712e-03, -1.3617e-02,  2.2561e-02,  3.5573e-03,\n",
      "        -3.5272e-02,  3.2409e-02, -1.7102e-02, -3.7208e-03, -3.5295e-02,\n",
      "         2.9214e-05,  3.2469e-02, -2.8521e-02,  2.6117e-02, -2.0924e-02,\n",
      "         2.8861e-02, -4.7595e-03,  1.5049e-02,  2.0952e-02,  1.7727e-02,\n",
      "        -7.1344e-03,  8.3986e-03, -1.1348e-02, -2.4246e-02, -1.8711e-02,\n",
      "        -2.7574e-02, -8.9653e-03,  2.2469e-03, -1.0117e-02, -2.0409e-02,\n",
      "        -1.5486e-02,  2.8177e-02,  1.9568e-02, -2.4471e-02, -3.6854e-02,\n",
      "         1.2238e-02,  2.2223e-02, -2.1585e-03,  3.8972e-02,  2.8422e-02,\n",
      "        -1.0385e-03,  1.5670e-02, -1.9265e-04, -4.9204e-03, -1.3857e-02,\n",
      "        -1.9240e-02,  1.8079e-02,  2.4470e-03,  2.5575e-02, -1.8430e-02,\n",
      "         2.4753e-02,  2.9459e-02, -7.6748e-03, -3.6532e-02,  1.4507e-02,\n",
      "         2.4351e-02, -2.5869e-02,  2.6674e-02, -2.0542e-02,  3.0543e-02,\n",
      "        -6.3780e-03,  2.0977e-02, -9.5392e-03, -1.7366e-02,  1.4887e-02,\n",
      "        -4.7802e-03,  1.2668e-02, -2.0510e-02, -6.0718e-03, -2.7514e-02,\n",
      "        -4.0344e-03,  2.2237e-02,  7.5749e-03,  2.9482e-02, -3.0244e-02,\n",
      "         1.3207e-02, -2.4978e-02, -3.0169e-02, -3.3206e-02, -1.2828e-02,\n",
      "         1.7542e-02,  9.3097e-03, -2.2190e-02, -3.0330e-02, -3.0502e-02,\n",
      "         1.3080e-02,  5.3351e-03, -3.2746e-03, -1.1467e-02,  3.1697e-02,\n",
      "         3.2552e-02, -1.4878e-02,  2.0988e-02,  9.5983e-03,  2.2788e-02,\n",
      "         3.3397e-02, -2.7293e-02, -1.2636e-02,  2.6414e-02,  2.5546e-02,\n",
      "         1.8416e-02, -1.1299e-02, -6.4840e-03, -1.3196e-02, -1.2646e-02,\n",
      "        -2.3590e-03,  1.1196e-02,  2.9218e-02,  2.8578e-02,  3.9928e-03,\n",
      "        -2.9476e-02, -1.2824e-03, -4.9996e-03, -3.0912e-02, -2.7415e-02,\n",
      "        -8.7009e-04, -2.4810e-02,  3.5486e-02, -1.6445e-02, -2.2986e-02,\n",
      "        -1.1770e-02,  2.5645e-02, -2.2834e-02, -1.8104e-02,  8.0288e-07,\n",
      "         1.6289e-02, -6.1014e-03, -3.9131e-03, -1.8274e-03, -1.2634e-02,\n",
      "         1.0475e-02,  1.3431e-02,  1.1297e-02, -8.3397e-03, -1.5321e-02,\n",
      "         2.8070e-02,  3.4235e-02,  2.7248e-02,  7.6153e-03,  2.3511e-02,\n",
      "         3.3120e-02, -1.4142e-02, -7.1815e-03, -2.9066e-02,  5.7856e-03,\n",
      "         3.1139e-02, -2.5266e-02, -2.0943e-02,  1.1031e-02,  1.5110e-02,\n",
      "        -5.1282e-03, -2.7593e-03,  2.4263e-02, -2.5519e-02, -2.8943e-02,\n",
      "         4.9906e-03,  2.5313e-02, -3.3570e-02, -1.7758e-02, -1.7442e-02,\n",
      "        -7.3174e-03, -2.5156e-03,  1.5853e-02,  3.0923e-02,  9.0777e-03,\n",
      "        -1.1305e-02, -2.0434e-02,  3.6863e-02,  1.0963e-02, -8.4529e-04,\n",
      "        -5.8875e-03, -1.9398e-02, -1.9650e-02,  1.3837e-02, -7.7071e-03,\n",
      "        -3.3330e-03,  1.4798e-02,  2.0410e-02,  1.8322e-02,  1.0714e-02,\n",
      "        -1.0327e-02, -1.8501e-02,  1.1813e-02,  3.2975e-02, -3.2296e-02,\n",
      "        -8.9811e-03, -2.0330e-02,  3.7448e-02, -2.1499e-02, -2.1624e-03,\n",
      "         2.8769e-02,  2.4458e-02,  2.9380e-03,  3.2560e-02, -1.8200e-02,\n",
      "        -1.5639e-03, -1.4089e-02, -1.2512e-03, -2.7894e-02,  9.2592e-03,\n",
      "        -2.8415e-02,  1.4874e-03, -1.4637e-03, -2.2018e-02, -2.4508e-02,\n",
      "         2.0387e-02, -1.3228e-02, -1.8964e-02,  2.5687e-03,  1.0818e-02,\n",
      "        -2.4259e-02, -1.5597e-02, -1.1724e-02, -2.0052e-02,  3.1938e-02,\n",
      "        -1.1785e-02,  5.0260e-03,  4.4063e-03,  1.2553e-02,  5.5418e-03,\n",
      "        -2.6349e-02,  1.0970e-02,  2.5152e-02, -2.3966e-02,  9.5622e-03,\n",
      "        -2.2803e-02,  4.5508e-03,  4.7004e-03,  1.8137e-02, -1.6467e-02,\n",
      "        -2.4051e-02,  2.9546e-02, -1.9619e-02,  1.6583e-02,  2.8604e-02,\n",
      "         1.2901e-02,  1.0616e-02, -3.5394e-03,  2.5003e-02,  1.2334e-02,\n",
      "         2.0511e-03,  3.2880e-02,  2.6807e-02,  1.9198e-02, -3.3208e-02,\n",
      "        -2.5054e-02,  2.2808e-02, -2.2671e-02, -3.3846e-02,  3.3099e-02,\n",
      "        -5.7233e-03,  1.6150e-02, -3.6046e-02,  4.0221e-02, -8.1994e-03,\n",
      "        -2.2039e-03, -1.2581e-02,  1.9343e-02, -4.4294e-04,  6.7418e-03,\n",
      "         2.9366e-02, -3.1293e-02,  2.5442e-02,  2.7768e-02, -1.3832e-02,\n",
      "         3.6514e-03, -2.5157e-04, -8.2567e-04, -2.7906e-02, -2.9460e-02,\n",
      "        -2.9174e-02,  1.9765e-02,  6.9612e-03,  3.6563e-02,  1.1701e-02,\n",
      "        -5.5258e-03, -1.9261e-02, -3.0582e-02, -1.0862e-02,  3.0578e-02,\n",
      "         1.1807e-02,  3.5590e-02,  1.7052e-03, -2.5516e-02, -1.0803e-03,\n",
      "         2.1187e-02,  1.0730e-02, -5.8144e-03,  5.8831e-03, -5.0459e-03,\n",
      "         3.1481e-02,  3.4726e-02, -2.5817e-02, -3.2473e-02, -7.0917e-04,\n",
      "         3.3836e-02, -6.2723e-03,  3.5839e-02,  5.7023e-03,  1.5207e-03,\n",
      "         2.0183e-02, -2.3035e-02,  1.3299e-02, -1.9650e-02,  2.8831e-02,\n",
      "         3.0551e-02, -3.1640e-02,  2.6504e-02, -1.5091e-02,  2.1012e-02,\n",
      "        -9.0652e-04,  5.0608e-03, -1.1343e-02,  1.2350e-02,  3.4610e-02,\n",
      "         7.6276e-03,  2.2427e-02,  3.1758e-02, -1.4791e-02,  2.5577e-03,\n",
      "         2.2627e-02,  2.0901e-05,  3.6422e-02, -1.5780e-02,  2.4152e-02,\n",
      "         1.4305e-02, -5.3511e-03,  6.8002e-03,  1.1533e-02, -1.9675e-02,\n",
      "         3.1904e-02,  2.3336e-03,  7.2720e-03, -1.8607e-04,  5.9276e-04,\n",
      "        -1.2084e-02,  1.5549e-02,  3.2147e-02, -5.2821e-03,  1.4493e-02,\n",
      "         2.0763e-02,  2.0185e-02, -1.2957e-03,  1.8242e-02, -2.4092e-02,\n",
      "        -1.4730e-02, -2.5910e-02, -2.2783e-02,  2.5986e-02,  1.4884e-02,\n",
      "        -2.1428e-02, -5.3231e-03,  3.0473e-02, -3.0744e-02, -3.5251e-02,\n",
      "         1.6652e-02,  1.3277e-02,  3.4063e-02, -3.5856e-02,  3.5514e-02,\n",
      "        -1.3771e-02, -3.3850e-02, -2.1893e-02, -2.3942e-02, -1.4501e-02,\n",
      "         3.9424e-02,  2.3012e-02, -2.1133e-02,  5.4577e-03,  3.1961e-02,\n",
      "        -1.2574e-03,  1.8248e-02,  3.4852e-02,  2.6734e-02,  9.7504e-03,\n",
      "         2.5273e-02,  2.1452e-02,  3.4390e-02, -6.8567e-03,  9.4528e-03],\n",
      "       requires_grad=True)}, 'fc2': {'size': 5000, 'shape': (10, 500), 'weights': array([-0.10272241,  0.00056956,  0.04580941, ..., -0.05005429,\n",
      "        0.07446207,  0.02471875], dtype=float32), 'bias': Parameter containing:\n",
      "tensor([-0.0217, -0.0097, -0.0336,  0.0196, -0.0362,  0.0293, -0.0207,  0.0175,\n",
      "         0.0783, -0.0240], requires_grad=True)}}\n"
     ]
    }
   ],
   "source": [
    "cw = compression(net, random_seed=123)\n",
    "print(cw)\n",
    "torch.save(cw, './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0043, -0.1102,  0.0247,  0.0222, -0.0254,  0.1691,  0.1220, -0.1632,\n",
       "         0.0741, -0.3533, -0.0546,  0.0616, -0.0791, -0.0884, -0.1745, -0.0998,\n",
       "         0.2434,  0.2171,  0.1365,  0.0053], requires_grad=True)"
      ]
     },
     "execution_count": 987,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw['conv1']['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the array:  400\n",
      "Length of one array element in bytes:  4\n",
      "Total bytes consumed by the elements of the array:  1600\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the array: \", compressed_flattened_conv1_orig.size)\n",
    "print(\"Length of one array element in bytes: \", compressed_flattened_conv1_orig.itemsize)\n",
    "print(\"Total bytes consumed by the elements of the array: \", compressed_flattened_conv1_orig.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the array:  500\n",
      "Length of one array element in bytes:  4\n",
      "Total bytes consumed by the elements of the array:  2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the array: \", compressed_flattened_conv1_masked.size)\n",
    "print(\"Length of one array element in bytes: \", compressed_flattened_conv1_masked.itemsize)\n",
    "print(\"Total bytes consumed by the elements of the array: \", compressed_flattened_conv1_masked.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the array:  400\n",
      "Length of one array element in bytes:  4\n",
      "Total bytes consumed by the elements of the array:  1600\n"
     ]
    }
   ],
   "source": [
    "nonzero_flattened_conv1 = flattened_conv1[flattened_conv1 != 0]\n",
    "print(\"Size of the array: \", nonzero_flattened_conv1.size)\n",
    "print(\"Length of one array element in bytes: \", nonzero_flattened_conv1.itemsize)\n",
    "print(\"Total bytes consumed by the elements of the array: \", nonzero_flattened_conv1.nbytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 20.00%\n",
      "Sparsity in conv2.weight: 20.00%\n",
      "Sparsity in fc1.weight: 20.00%\n",
      "Sparsity in fc2.weight: 20.00%\n",
      "Global sparsity: 20.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model_1.conv1.weight == 0))\n",
    "        / float(model_1.conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model_1.conv2.weight == 0))\n",
    "        / float(model_1.conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model_1.fc1.weight == 0))\n",
    "        / float(model_1.fc1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model_1.fc2.weight == 0))\n",
    "        / float(model_1.fc2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model_1.conv1.weight == 0)\n",
    "            + torch.sum(model_1.conv2.weight == 0)\n",
    "            + torch.sum(model_1.fc1.weight == 0)\n",
    "            + torch.sum(model_1.fc2.weight == 0)\n",
    "\n",
    "        )\n",
    "        / float(\n",
    "            model_1.conv1.weight.nelement()\n",
    "            + model_1.conv2.weight.nelement()\n",
    "            + model_1.fc1.weight.nelement()\n",
    "            + model_1.fc2.weight.nelement()\n",
    "\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 5, 5])\n",
      "torch.Size([20])\n",
      "torch.Size([50, 20, 5, 5])\n",
      "torch.Size([50])\n",
      "torch.Size([500, 800])\n",
      "torch.Size([500])\n",
      "torch.Size([10, 500])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "     print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on all digits: 98.450 %\n",
      "Accuracy of the network digit 0: 87.449 %\n",
      "Accuracy of the network digit 1: 86.079 %\n",
      "Accuracy of the network digit 2: 88.081 %\n",
      "Accuracy of the network digit 3: 87.921 %\n",
      "Accuracy of the network digit 4: 85.540 %\n",
      "Accuracy of the network digit 5: 85.987 %\n",
      "Accuracy of the network digit 6: 88.100 %\n",
      "Accuracy of the network digit 7: 86.284 %\n",
      "Accuracy of the network digit 8: 87.372 %\n",
      "Accuracy of the network digit 9: 84.539 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "correct_per_digit = np.zeros(10)\n",
    "total_per_digit = np.zeros(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader):\n",
    "        inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
    "        \n",
    "        # net 1\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # compute accuracy per digit label\n",
    "        for i in range(10):\n",
    "            total_per_digit[i] += labels.tolist().count(i)\n",
    "            if i in labels:\n",
    "                idx = labels.tolist().index(i)\n",
    "                correct_per_digit[i] += (predicted[idx] == i).sum().item()\n",
    "            \n",
    "print('Accuracy of the network on all digits: %0.3f %%' % (100 * correct / total))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of the network digit %d: %0.3f %%' % (i, 100 * correct_per_digit[i] / total_per_digit[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[857. 977. 909. 888. 840. 767. 844. 887. 851. 853.]\n",
      "[ 980. 1135. 1032. 1010.  982.  892.  958. 1028.  974. 1009.]\n",
      "total trainning batch number: 15000\n"
     ]
    }
   ],
   "source": [
    "print(correct_per_digit)\n",
    "print(total_per_digit)\n",
    "print('total trainning batch number: {}'.format(len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
